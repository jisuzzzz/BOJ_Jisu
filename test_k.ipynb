{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjbE9U+vq7kdBax76sqYUt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jisuzzzz/BOJ_Jisu/blob/main/test_k.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BUlL5xtZrCGp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 주어진 데이터에서 두 변수 X와 Y의 관계를 분석하고자 합니다. 데이터의 X,Y값의 쌍은 다음과 같습니다.\n",
        "# (1,1), (1,2), (2,3), (3,3)\n",
        "# 두 변수가 선형적인 관계에 있다고 가정하고 X 변수를 입력으로하여 Y변수의 값을 예측하기 위한 가설함수로 가장 적절한 것은?"
      ],
      "metadata": {
        "id": "98RPbeR7xTPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 데이터 정의\n",
        "x_data = torch.tensor([1.0, 1.0, 2.0, 3.0])\n",
        "y_data = torch.tensor([1.0, 2.0, 3.0, 3.0])\n",
        "\n",
        "# 변수 초기화\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "b = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# 학습률 설정\n",
        "lr = 0.1\n",
        "\n",
        "# Forward pass\n",
        "y_pred = w * x_data + b\n",
        "loss = ((y_pred - y_data)**2).mean()\n",
        "\n",
        "# Backward pass\n",
        "loss.backward()\n",
        "\n",
        "# Gradient Descent\n",
        "with torch.no_grad():\n",
        "    w -= lr * w.grad\n",
        "    b -= lr * b.grad\n",
        "\n",
        "# 기울기 초기화\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print(f'Updated w: {w.item()}')\n",
        "print(f'Updated b: {b.item()}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXI3m5_KzMTJ",
        "outputId": "297f0904-6bea-4249-b25e-72ac864a72d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated w: 0.800000011920929\n",
            "Updated b: 0.8999999761581421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "data = pickle.load(open(\"docs.pkl\",\"rb\"))"
      ],
      "metadata": {
        "id": "NAfB8rVh0djn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts = data['train'][12]['words']\n",
        "\n",
        "sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "top_5_words = sorted_word_counts[:5]\n",
        "\n",
        "result = ', '.join([word for word, count in top_5_words])\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1C0Skii01Ky",
        "outputId": "c0612fd2-bdd6-4e9c-99c6-99bb5dcfdb5b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the, in, to, a, conte\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['train'][12].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLbTf5Y92LvD",
        "outputId": "850ee76d-f6ac-4c95-bfb4-2baddddbf113"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['text', 'words', 'category', 'embedding'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(set1, set2):\n",
        "    intersection = len(set1.intersection(set2))\n",
        "    union = len(set1.union(set2))\n",
        "    return intersection / union if union != 0 else 0\n",
        "\n",
        "# 각 문서의 단어들을 집합으로 변환\n",
        "word_sets = [set(doc['text'].split()) for doc in data['train']]\n",
        "\n",
        "# 31번 문서와 나머지 문서들 간의 Jaccard 유사도 계산\n",
        "similarity_scores = []\n",
        "for i, word_set in enumerate(word_sets):\n",
        "    if i != 31:\n",
        "        similarity = jaccard_similarity(word_sets[31], word_set)\n",
        "        similarity_scores.append((i, similarity))\n",
        "\n",
        "# 유사도가 높은 순서로 정렬\n",
        "sorted_similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# 상위 5개의 문서 선택\n",
        "top_5_docs = sorted_similarity_scores[:5]\n",
        "\n",
        "# 결과 출력\n",
        "print([doc[0] for doc in top_5_docs])\n",
        "top_5_categories = [data['train'][doc[0]]['category'] for doc in top_5_docs]\n",
        "print(' '.join(top_5_categories))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCQ3OR6343GC",
        "outputId": "59232277-23cf-4751-a71d-f4a8df7ea144"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[182, 323, 659, 302, 749]\n",
            "technologie technologie technologie technologie technologie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(set1, set2):\n",
        "  if len(set1 | set2)==0:\n",
        "    return 0\n",
        "  return len(set1&set2)/len(set1|set2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBQNrCcQ5aWM",
        "outputId": "d96c1463-7686-4a13-ab34-47d5c05c50ec"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[109, 886, 854, 669, 50]\n",
            "technologie technologie technologie technologie technologie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(set1, set2):\n",
        "    if len(set1 | set2) == 0:\n",
        "        return 0\n",
        "    return len(set1 & set2) / len(set1 | set2)\n",
        "\n",
        "# 각 문서의 단어들을 집합으로 변환\n",
        "word_sets = [set(doc['text'].split()) for doc in data['train']]\n",
        "\n",
        "# 31번 문서와 나머지 문서들 간의 Jaccard 유사도 계산\n",
        "similarity_scores = []\n",
        "for i, word_set in enumerate(word_sets):\n",
        "    if i != 31:  # 31번 문서는 제외 (인덱스는 30)\n",
        "        similarity = jaccard_similarity(word_sets[31], word_set)\n",
        "        similarity_scores.append((i, similarity))\n",
        "\n",
        "# 유사도가 높은 순서로 정렬\n",
        "sorted_similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# 상위 5개의 문서 선택\n",
        "top_5_docs = sorted_similarity_scores[:5]\n",
        "\n",
        "# 상위 5개의 문서의 번호 출력\n",
        "top_5_doc_numbers = [doc[0] for doc in top_5_docs]\n",
        "print(top_5_doc_numbers)\n",
        "\n",
        "# 상위 5개의 문서의 카테고리 출력\n",
        "top_5_categories = [data['train'][doc[0]]['category'] for doc in top_5_docs]\n",
        "print(' '.join(top_5_categories))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e6I7ibO62YR",
        "outputId": "1ec69a4c-23e2-4dab-c030-25ec29b87dd5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[182, 323, 659, 302, 749]\n",
            "technologie technologie technologie technologie technologie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def jaccard_similarity(set1, set2):\n",
        "    if len(set1 | set2) == 0:\n",
        "        return 0\n",
        "    return len(set1 & set2) / len(set1 | set2)\n",
        "\n",
        "# 각 단어가 포함된 문서들의 집합을 구함\n",
        "word_documents = defaultdict(set)\n",
        "for i, doc in enumerate(data['train']):\n",
        "    words = set(doc['text'].split())\n",
        "    for word in words:\n",
        "        word_documents[word].add(i)\n",
        "\n",
        "# 'game'이 포함된 문서들의 집합\n",
        "game_documents = word_documents['game']\n",
        "\n",
        "# 'game'과 다른 단어들의 Jaccard 유사도 계산\n",
        "similarity_scores = []\n",
        "for word, documents in word_documents.items():\n",
        "    if word != 'game':\n",
        "        similarity = jaccard_similarity(game_documents, documents)\n",
        "        similarity_scores.append((word, similarity))\n",
        "\n",
        "# 유사도가 높은 순서로 정렬\n",
        "sorted_similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# 상위 5개의 단어 출력\n",
        "top_5_words = [word for word, similarity in sorted_similarity_scores[:5]]\n",
        "print(top_5_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fl6529J8rqp",
        "outputId": "e4bc0c66-8709-4084-94eb-d98bfa1f6a3c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['games', 'house,', 'games.', 'Nintendo', 'upload']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import string\n",
        "\n",
        "def jaccard_similarity(set1, set2):\n",
        "    if len(set1 | set2) == 0:\n",
        "        return 0\n",
        "    return len(set1 & set2) / len(set1 | set2)\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "# 각 단어가 포함된 문서들의 집합을 구함\n",
        "word_documents = defaultdict(set)\n",
        "for i, doc in enumerate(data['train']):\n",
        "    words = set(remove_punctuation(doc['text']).split())\n",
        "    for word in words:\n",
        "        word_documents[word].add(i)\n",
        "\n",
        "# 'game'이 포함된 문서들의 집합\n",
        "game_documents = word_documents['game']\n",
        "\n",
        "# 'game'과 다른 단어들의 Jaccard 유사도 계산\n",
        "similarity_scores = []\n",
        "for word, documents in word_documents.items():\n",
        "    if word != 'game':\n",
        "        similarity = jaccard_similarity(game_documents, documents)\n",
        "        similarity_scores.append((word, similarity))\n",
        "\n",
        "# 유사도가 높은 순서로 정렬\n",
        "sorted_similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# 상위 5개의 단어 출력\n",
        "top_5_words = [word for word, similarity in sorted_similarity_scores[:5]]\n",
        "print(top_5_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7q8IISS9Zda",
        "outputId": "4f8fd233-796e-4e04-9883-946a33c3fda2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ball', 'games', 'video', 'runners', 'Sony']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "print(cosine_similarity(data[\"train_vectors\"],data[\"test1_vectors\"])[0][1])"
      ],
      "metadata": {
        "id": "Vx_VwjZW954r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "# 1. 각 문서에 대해 단어의 등장 횟수 계산\n",
        "word_counts = [Counter(remove_punctuation(doc['text']).split()) for doc in data['train']]\n",
        "\n",
        "# 2. 전체 문서에 대해 각 단어가 몇 개의 문서에 등장하는지 계산\n",
        "document_frequency = Counter()\n",
        "for word_count in word_counts:\n",
        "    for word in word_count.keys():\n",
        "        document_frequency[word] += 1\n",
        "\n",
        "# 3. 31번 문서에 대해 TF-IDF 점수 계산\n",
        "word_count_31 = word_counts[31]\n",
        "total_words_31 = sum(word_count_31.values())\n",
        "tfidf_scores = []\n",
        "for word, count in word_count_31.items():\n",
        "    tf = count / total_words_31\n",
        "    idf = math.log(len(data['train']) / document_frequency[word])\n",
        "    tfidf = tf * idf\n",
        "    tfidf_scores.append((word, tfidf))\n",
        "\n",
        "# TF-IDF 점수가 높은 순서로 정렬\n",
        "sorted_tfidf_scores = sorted(tfidf_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# 상위 5개의 단어 출력\n",
        "top_5_words = [word for word, score in sorted_tfidf_scores[:5]]\n",
        "print(top_5_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99rrDe9t_NPm",
        "outputId": "0c266bb2-f13b-40d4-f10d-b37073c35983"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['laptops', 'Negroponte', 'laptop', 'child', 'Digital']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 31번 문서의 임베딩 벡터\n",
        "embed_31 = data['train'][31]['embedding']\n",
        "\n",
        "# 모든 문서의 임베딩 벡터\n",
        "all_embeddings = [doc['embedding'] for doc in data['train']]\n",
        "\n",
        "# 31번 문서와 모든 문서간의 코사인 유사도 계산\n",
        "cosine_similarities = cosine_similarity([embed_31], all_embeddings)\n",
        "\n",
        "# 코사인 유사도가 높은 순서로 정렬 (자기 자신 제외)\n",
        "similar_docs = sorted(enumerate(cosine_similarities[0]), key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "# 문서 번호와 카테고리 출력\n",
        "doc_numbers = [doc[0] for doc in similar_docs]\n",
        "categories = [data['train'][doc[0]]['category'] for doc in similar_docs]\n",
        "print(doc_numbers)\n",
        "print(' '.join(categories))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ygw2Jid0_kH5",
        "outputId": "2ff403be-c59a-4ffb-9dcd-078cdeeb537f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[31, 182, 749, 72, 66]\n",
            "technologie technologie technologie technologie technologie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# 자카드 유사도 계산\n",
        "def jaccard_similarity(set1, set2):\n",
        "    if len(set1 | set2) == 0:\n",
        "        return 0\n",
        "    return len(set1 & set2) / len(set1 | set2)\n",
        "\n",
        "doc_31_words = set(data['train'][31]['text'].split())\n",
        "jaccard_scores = [jaccard_similarity(doc_31_words, set(doc['text'].split())) for doc in data['train']]\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "embed_31 = [data['train'][31]['embedding']]\n",
        "all_embeddings = [doc['embedding'] for doc in data['train']]\n",
        "cosine_similarities = cosine_similarity(embed_31, all_embeddings)[0]\n",
        "\n",
        "# 두 유사도의 상관계수 계산\n",
        "correlation_coefficient = np.corrcoef(jaccard_scores, cosine_similarities)[0, 1]\n",
        "\n",
        "print(correlation_coefficient)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEFb0neHAijk",
        "outputId": "57e6660f-799b-4609-dc80-e2a3c641eb5f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5012315451366166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 학습 데이터\n",
        "X_train = [doc['embedding'] for doc in data['train']]\n",
        "y_train = [doc['category'] for doc in data['train']]\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Softmax Regression 모델 학습\n",
        "clf = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "clf.fit(X_train, y_train_encoded)\n",
        "\n",
        "# 테스트 데이터\n",
        "X_test = [doc['embedding'] for doc in data['test']]\n",
        "\n",
        "# 예측\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# 예측된 레이블을 원래의 문자열로 변환\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "# 출력\n",
        "print(' '.join(y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jem7BhP2BFL-",
        "outputId": "133fbae5-87e6-499e-e0e2-e6b5314dbfb6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "food business historical medical entertainment sport entertainment historical technologie politics\n"
          ]
        }
      ]
    }
  ]
}